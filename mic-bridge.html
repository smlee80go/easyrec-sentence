<!DOCTYPE html>
<html>
<head>
<meta charset="utf-8">
<title>ğŸ™ï¸ MicBridge</title>
<style>
body { margin:0; padding:10px; font:13px sans-serif; background:#1a1a2e; color:#ddd; min-width:280px; }
.status { display:flex; align-items:center; gap:8px; margin-bottom:8px; }
.dot { width:10px; height:10px; border-radius:50%; }
.dot.ready { background:#4CAF50; }
.dot.recording { background:#f44336; animation:pulse 1s infinite; }
.dot.error { background:#ff9800; }
@keyframes pulse { 0%,100%{opacity:1} 50%{opacity:0.3} }
#levelBar { height:6px; background:#333; border-radius:3px; overflow:hidden; }
#levelFill { height:100%; width:0%; background:linear-gradient(90deg,#4CAF50,#FFC107,#f44336); transition:width 50ms; }
.info { font-size:11px; color:#888; margin-top:6px; }
</style>
</head>
<body>
<div class="status">
  <div class="dot" id="statusDot"></div>
  <span id="statusText">ì¤€ë¹„ ì¤‘...</span>
</div>
<div id="levelBar"><div id="levelFill"></div></div>
<div class="info" id="info">ì´ ì°½ì„ ë‹«ì§€ ë§ˆì„¸ìš”. ë…¹ìŒ ì¤‘ ë§ˆì´í¬ ì—°ê²° ìœ ì§€ë©ë‹ˆë‹¤.</div>

<script>
const opener = window.opener;
let audioCtx = null;
let mediaStream = null;
let workletNode = null;
let workletRegistered = false;
let analyser = null;
let levelRAF = null;
let isRecording = false;
const CHUNK_SIZE = 8192;

const statusDot = document.getElementById('statusDot');
const statusText = document.getElementById('statusText');
const levelFill = document.getElementById('levelFill');
const info = document.getElementById('info');

function setStatus(state, text) {
  statusDot.className = 'dot ' + state;
  statusText.textContent = text;
}

function send(data, transfer) {
  if (opener && !opener.closed) {
    try { opener.postMessage(data, '*', transfer || []); } catch(e) {}
  }
}

// ===== ë©”ì‹œì§€ ìˆ˜ì‹  =====
window.addEventListener('message', async (e) => {
  const msg = e.data;
  if (!msg || !msg.cmd) return;
  try {
    switch(msg.cmd) {
      case 'enumerate': await doEnumerate(); break;
      case 'start': await doStart(msg); break;
      case 'stop': doStop(); break;
      case 'pause': isRecording = false; setStatus('ready', 'ì¼ì‹œì •ì§€'); break;
      case 'resume': isRecording = true; setStatus('recording', 'ğŸ”´ ë…¹ìŒ ì¤‘'); break;
    }
  } catch(err) {
    setStatus('error', 'ì˜¤ë¥˜: ' + err.message);
    send({type:'error', message: err.message});
  }
});

// ===== ì¥ì¹˜ ì—´ê±° =====
async function doEnumerate() {
  setStatus('ready', 'ë§ˆì´í¬ ê¶Œí•œ ìš”ì²­ ì¤‘...');
  try {
    const tempStream = await navigator.mediaDevices.getUserMedia({audio:true});
    tempStream.getTracks().forEach(t => t.stop());
  } catch(e) {
    setStatus('error', 'ë§ˆì´í¬ ê¶Œí•œ ê±°ë¶€ë¨');
    send({type:'devices', devices: []});
    return;
  }
  const devices = await navigator.mediaDevices.enumerateDevices();
  const audioInputs = devices.filter(d => d.kind === 'audioinput').map(d => ({
    deviceId: d.deviceId, label: d.label, kind: d.kind
  }));
  setStatus('ready', 'âœ… ë§ˆì´í¬ ì—°ê²°ë¨ (' + audioInputs.length + 'ê°œ)');
  send({type:'devices', devices: audioInputs});
}

// ===== ë…¹ìŒ ì‹œì‘ =====
async function doStart(msg) {
  doStop(); // ì´ì „ ì„¸ì…˜ ì •ë¦¬

  const constraints = { audio: {
    echoCancellation: false, noiseSuppression: false, autoGainControl: false
  }};
  if (msg.deviceId && msg.deviceId !== 'default' && msg.deviceId !== '') {
    constraints.audio.deviceId = {exact: msg.deviceId};
  }
  if (msg.channels >= 2) constraints.audio.channelCount = 2;

  setStatus('ready', 'ë§ˆì´í¬ ì ‘ê·¼ ì¤‘...');
  mediaStream = await navigator.mediaDevices.getUserMedia(constraints);

  audioCtx = new AudioContext({sampleRate: msg.sampleRate || 48000});
  if (audioCtx.state === 'suspended') await audioCtx.resume();

  const source = audioCtx.createMediaStreamSource(mediaStream);

  // ë ˆë²¨ ë¯¸í„°ìš© ë¶„ì„ê¸°
  analyser = audioCtx.createAnalyser();
  analyser.fftSize = 2048;
  source.connect(analyser);

  // PCM ìº¡ì²˜ìš© AudioWorklet
  const workletCode = `
    class RecorderProcessor extends AudioWorkletProcessor {
      constructor() { super(); this.sz=${CHUNK_SIZE}; this.bL=new Float32Array(this.sz); this.bR=new Float32Array(this.sz); this.p=0; }
      process(inputs) {
        const inp=inputs[0]; if(!inp||!inp[0]) return true;
        for(let i=0;i<inp[0].length;i++){
          this.bL[this.p]=inp[0][i]; this.bR[this.p]=inp.length>=2?inp[1][i]:inp[0][i]; this.p++;
          if(this.p>=this.sz){
            this.port.postMessage({left:new Float32Array(this.bL),right:new Float32Array(this.bR)});
            this.bL=new Float32Array(this.sz); this.bR=new Float32Array(this.sz); this.p=0;
          }
        }
        return true;
      }
    }
    registerProcessor('rec-proc',RecorderProcessor);
  `;
  const blob = new Blob([workletCode], {type:'application/javascript'});
  const url = URL.createObjectURL(blob);
  if (!workletRegistered) {
    try { await audioCtx.audioWorklet.addModule(url); workletRegistered = true; } catch(e) { workletRegistered = true; }
  }
  URL.revokeObjectURL(url);

  workletNode = new AudioWorkletNode(audioCtx, 'rec-proc', {
    numberOfInputs:1, numberOfOutputs:0, channelCount: msg.channels >= 2 ? 2 : 1
  });
  workletNode.port.onmessage = (e) => {
    if (!isRecording) return;
    send({type:'pcm', left:e.data.left, right:e.data.right}, [e.data.left.buffer, e.data.right.buffer]);
  };
  source.connect(workletNode);

  isRecording = true;
  startLevelMeter();
  setStatus('recording', 'ğŸ”´ ë…¹ìŒ ì¤‘');
  send({type:'started', sampleRate: audioCtx.sampleRate});
}

// ===== ë…¹ìŒ ì¤‘ì§€ =====
function doStop() {
  const wasRecording = isRecording;
  isRecording = false;
  if (levelRAF) { cancelAnimationFrame(levelRAF); levelRAF = null; }
  if (workletNode) { try { workletNode.disconnect(); } catch(e){} workletNode = null; }
  if (analyser) { try { analyser.disconnect(); } catch(e){} analyser = null; }
  if (mediaStream) { mediaStream.getTracks().forEach(t => t.stop()); mediaStream = null; }
  if (audioCtx) { audioCtx.close().catch(()=>{}); audioCtx = null; workletRegistered = false; }
  levelFill.style.width = '0%';
  if (wasRecording) {
    setStatus('ready', 'âœ… ë…¹ìŒ ì™„ë£Œ');
    send({type:'stopped'});
  }
}

// ===== ë ˆë²¨ ë¯¸í„° =====
function startLevelMeter() {
  if (!analyser) return;
  const buf = new Float32Array(analyser.fftSize);
  function tick() {
    if (!analyser || !isRecording) return;
    analyser.getFloatTimeDomainData(buf);
    let sum = 0;
    for (let i=0; i<buf.length; i++) sum += buf[i]*buf[i];
    const rms = Math.sqrt(sum/buf.length);
    const db = rms > 0 ? 20*Math.log10(rms) : -100;
    const pct = Math.max(0, Math.min(100, (db+60)/60*100));
    levelFill.style.width = pct + '%';
    send({type:'level', rms, db, percent:pct});
    levelRAF = requestAnimationFrame(tick);
  }
  levelRAF = requestAnimationFrame(tick);
}

// ===== ì´ˆê¸°í™” =====
setStatus('ready', 'âœ… ì¤€ë¹„ë¨');
send({type:'ready'});

// opener ë‹«íˆë©´ ìë™ ì¢…ë£Œ
setInterval(() => { if (!opener || opener.closed) window.close(); }, 3000);
</script>
</body>
</html>
