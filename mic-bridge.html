<!DOCTYPE html>
<html>
<head>
<meta charset="utf-8">
<title>ğŸ™ï¸ MicBridge</title>
<style>
body { margin:0; padding:10px; font:13px sans-serif; background:#1a1a2e; color:#ddd; min-width:280px; }
.status { display:flex; align-items:center; gap:8px; margin-bottom:8px; }
.dot { width:10px; height:10px; border-radius:50%; }
.dot.off { background:#666; }
.dot.on { background:#4CAF50; }
.dot.recording { background:#f44336; animation:pulse 1s infinite; }
.dot.error { background:#ff9800; }
@keyframes pulse { 0%,100%{opacity:1} 50%{opacity:0.3} }
#levelBar { height:6px; background:#333; border-radius:3px; overflow:hidden; }
#levelFill { height:100%; width:0%; background:linear-gradient(90deg,#4CAF50,#FFC107,#f44336); transition:width 50ms; }
.info { font-size:11px; color:#888; margin-top:6px; }
</style>
</head>
<body>
<div class="status">
  <div class="dot off" id="statusDot"></div>
  <span id="statusText">ì¤€ë¹„ ì¤‘...</span>
</div>
<div id="levelBar"><div id="levelFill"></div></div>
<div class="info" id="info">ì´ ì°½ì„ ë‹«ì§€ ë§ˆì„¸ìš”. ë…¹ìŒ ì¤‘ ë§ˆì´í¬ ì—°ê²° ìœ ì§€ë©ë‹ˆë‹¤.</div>

<script>
const opener = window.opener;
let keepStream = null;
let recAudioCtx = null;
let workletNode = null;
let analyser = null;
let levelRAF = null;
let isRecording = false;
const CHUNK_SIZE = 8192;

const statusDot = document.getElementById('statusDot');
const statusText = document.getElementById('statusText');
const levelFill = document.getElementById('levelFill');

function setStatus(state, text) {
  statusDot.className = 'dot ' + state;
  statusText.textContent = text;
}

function send(data, transfer) {
  if (opener && !opener.closed) {
    try { opener.postMessage(data, '*', transfer || []); } catch(e) {}
  }
}

window.addEventListener('message', async (e) => {
  const msg = e.data;
  if (!msg || !msg.cmd) return;
  try {
    switch(msg.cmd) {
      case 'enumerate': await doEnumerate(msg.deviceId); break;
      case 'start': await doStart(msg); break;
      case 'stop': doStop(); break;
      case 'pause': isRecording = false; setStatus('on', 'â¸ ì¼ì‹œì •ì§€'); break;
      case 'resume': isRecording = true; setStatus('recording', 'ğŸ”´ ë…¹ìŒ ì¤‘'); break;
    }
  } catch(err) {
    console.error('Bridge error:', err);
    setStatus('error', 'ì˜¤ë¥˜: ' + err.message);
    send({type:'error', message: err.message});
  }
});

// ===== ì¥ì¹˜ ì—´ê±° + ìŠ¤íŠ¸ë¦¼ ìœ ì§€ =====
async function doEnumerate(deviceId) {
  setStatus('off', 'ë§ˆì´í¬ ê¶Œí•œ ìš”ì²­ ì¤‘...');
  if (keepStream) { keepStream.getTracks().forEach(t => t.stop()); keepStream = null; }
  try {
    const c = { audio: { echoCancellation:false, noiseSuppression:false, autoGainControl:false }};
    if (deviceId && deviceId !== 'default' && deviceId !== '') c.audio.deviceId = {exact:deviceId};
    keepStream = await navigator.mediaDevices.getUserMedia(c);
  } catch(e) {
    setStatus('error', 'ë§ˆì´í¬ ê¶Œí•œ ê±°ë¶€ë¨');
    send({type:'devices', devices:[]});
    return;
  }
  const devices = await navigator.mediaDevices.enumerateDevices();
  const audioInputs = devices.filter(d => d.kind === 'audioinput').map(d => ({
    deviceId: d.deviceId, label: d.label, kind: d.kind
  }));
  setStatus('on', 'ğŸ¤ ë§ˆì´í¬ ON (' + audioInputs.length + 'ê°œ)');
  send({type:'devices', devices: audioInputs});
}

// ===== ë…¹ìŒ ì‹œì‘ (ìŠ¤íŠ¸ë¦¼ ì¬ì‚¬ìš©) =====
async function doStart(msg) {
  cleanupRecSession();
  let stream = keepStream;
  if (!stream || stream.getAudioTracks().length === 0 || !stream.active) {
    const c = { audio: { echoCancellation:false, noiseSuppression:false, autoGainControl:false }};
    if (msg.deviceId && msg.deviceId !== 'default') c.audio.deviceId = {exact:msg.deviceId};
    if (msg.channels >= 2) c.audio.channelCount = 2;
    stream = await navigator.mediaDevices.getUserMedia(c);
    keepStream = stream;
  }
  recAudioCtx = new AudioContext({sampleRate: msg.sampleRate || 48000});
  if (recAudioCtx.state === 'suspended') await recAudioCtx.resume();
  const source = recAudioCtx.createMediaStreamSource(stream);
  analyser = recAudioCtx.createAnalyser();
  analyser.fftSize = 2048;
  source.connect(analyser);
  const spCh = msg.channels >= 2 ? 2 : 1;
  const code = `class RP extends AudioWorkletProcessor{constructor(){super();this.sz=${CHUNK_SIZE};this.bL=new Float32Array(this.sz);this.bR=new Float32Array(this.sz);this.p=0;}process(inputs){const inp=inputs[0];if(!inp||!inp[0])return true;for(let i=0;i<inp[0].length;i++){this.bL[this.p]=inp[0][i];this.bR[this.p]=inp.length>=2?inp[1][i]:inp[0][i];this.p++;if(this.p>=this.sz){this.port.postMessage({left:new Float32Array(this.bL),right:new Float32Array(this.bR)});this.bL=new Float32Array(this.sz);this.bR=new Float32Array(this.sz);this.p=0;}}return true;}}registerProcessor('rp',RP);`;
  const blob = new Blob([code], {type:'application/javascript'});
  const url = URL.createObjectURL(blob);
  try { await recAudioCtx.audioWorklet.addModule(url); } catch(e) {}
  URL.revokeObjectURL(url);
  workletNode = new AudioWorkletNode(recAudioCtx, 'rp', {numberOfInputs:1, numberOfOutputs:0, channelCount:spCh});
  workletNode.port.onmessage = (evt) => {
    if (!isRecording) return;
    send({type:'pcm', left:evt.data.left, right:evt.data.right}, [evt.data.left.buffer, evt.data.right.buffer]);
  };
  source.connect(workletNode);
  isRecording = true;
  startLevelMeter();
  setStatus('recording', 'ğŸ”´ ë…¹ìŒ ì¤‘');
  send({type:'started', sampleRate: recAudioCtx.sampleRate});
}

function cleanupRecSession() {
  isRecording = false;
  if (levelRAF) { cancelAnimationFrame(levelRAF); levelRAF = null; }
  if (workletNode) { try{workletNode.disconnect();}catch(e){} workletNode = null; }
  if (analyser) { try{analyser.disconnect();}catch(e){} analyser = null; }
  if (recAudioCtx) { recAudioCtx.close().catch(()=>{}); recAudioCtx = null; }
  levelFill.style.width = '0%';
}

function doStop() {
  const was = isRecording;
  cleanupRecSession();
  if (was) {
    setStatus('on', 'ğŸ¤ ë§ˆì´í¬ ON');
    send({type:'stopped'});
  }
}

function startLevelMeter() {
  if (!analyser) return;
  const buf = new Float32Array(analyser.fftSize);
  function tick() {
    if (!analyser) return;
    analyser.getFloatTimeDomainData(buf);
    let sum=0; for(let i=0;i<buf.length;i++) sum+=buf[i]*buf[i];
    const rms=Math.sqrt(sum/buf.length);
    const db=rms>0?20*Math.log10(rms):-100;
    const pct=Math.max(0,Math.min(100,(db+60)/60*100));
    levelFill.style.width=pct+'%';
    if(isRecording) send({type:'level',rms,db,percent:pct});
    levelRAF=requestAnimationFrame(tick);
  }
  levelRAF=requestAnimationFrame(tick);
}

setStatus('on', 'âœ… ì¤€ë¹„ë¨');
send({type:'ready'});
setInterval(()=>{if(!opener||opener.closed){if(keepStream)keepStream.getTracks().forEach(t=>t.stop());window.close();}},3000);
window.addEventListener('beforeunload',()=>{cleanupRecSession();if(keepStream){keepStream.getTracks().forEach(t=>t.stop());keepStream=null;}});
</script>
</body>
</html>
